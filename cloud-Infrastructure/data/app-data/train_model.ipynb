{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this notebook the model to classify the activities from the online.data file will be selected, train and exported.\n",
    "- We will train and compare several models, evaluating their performance to try to identify the better one. This model will be exported to a .dat.gz file to be used by our program to accurately classify whether the user is walking or running or walking.\n",
    "- For efficiency reasons we will not test the best parameters for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First, read the data from the file.\n",
    "- We are also separating the activity column from the others, since the activity column is the label.\n",
    "- The date and time columns are dropped since they have no use in the classification.\n",
    "- There seems to be no missing values in the dataset. Still, we are using an Imputer to, if missing values were to exist, replace them with the mean of their respective columns.\n",
    "- We use a scaler to force all the values to be in the same scale. The idea is to not have a specific column artifically mess with the classification for having values a lot higher or lower than the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.265 , -0.7814, -0.0076, -0.059 ,  0.0325, -2.9296],\n",
       "       [ 0.6722, -1.1233, -0.2344, -0.1757,  0.0208,  0.1269],\n",
       "       [ 0.4399, -1.4817,  0.0722, -0.9105,  0.1063, -2.4367],\n",
       "       ...,\n",
       "       [-0.3874, -1.2696, -0.2641, -0.8963,  0.2506,  0.58  ],\n",
       "       [-0.3047, -1.1782, -0.1363, -1.1958,  0.5059,  1.3119],\n",
       "       [-0.1926, -0.7112, -0.0832, -0.4192, -0.2741,  0.9312]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/output_training.data', delimiter=';')\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_imputed = imputer.fit_transform(data.drop(['activity', 'date', 'time'], axis=1))\n",
    "X = scaler.fit_transform(X_imputed)\n",
    "y = data['activity']\n",
    "X_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this phase we will select the models that we are going to train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class=\"auto\")))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('DT', DecisionTreeClassifier()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('GNB', GaussianNB()))\n",
    "models.append(('SVC', SVC(C = 1.0, kernel = 'rbf')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate each model using K-Fold validation. Without it, we would be relying on a single split between test and train which, depending on the distribution of data in the split, poorly impact our measures. With cross-validation we can have a more realiable measure, at the same time that we are able to use our whole set to train the model.\n",
    "The metric that we use to evaluate the model's performance is f1-score. F1-Score is more resistant to inbalanced datasets and often provides a more reliable and balanced metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model F1-Score:\n",
      "LR: F1-Score=0.837860 std=(0.004695)\n",
      "LDA: F1-Score=0.792139 std=(0.007012)\n",
      "DT: F1-Score=0.987359 std=(0.001238)\n",
      "KNN: F1-Score=0.988835 std=(0.001512)\n",
      "GNB: F1-Score=0.951092 std=(0.002205)\n",
      "SVC: F1-Score=0.985651 std=(0.000941)\n"
     ]
    }
   ],
   "source": [
    "# evaluate each model in turn\n",
    "print(\"Model F1-Score:\")\n",
    "f1_scores = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X, y, cv=kfold, scoring='f1')\n",
    "    \n",
    "    f1_scores.append(cv_results.mean())\n",
    "    msg = \"%s: F1-Score=%f std=(%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, select the model that performed the best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n"
     ]
    }
   ],
   "source": [
    "max_f1_score = max(f1_scores)\n",
    "index_max_f1_score = f1_scores.index(max_f1_score)\n",
    "\n",
    "chosen_model = models[index_max_f1_score]\n",
    "print(chosen_model[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The selected model will now be fitted with the whole set and exported. This will be the model that our application will use to try to classify whether the user is running or walking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model/classifier.dat.gz']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_to_export = chosen_model[1]\n",
    "\n",
    "model_to_export.fit(X, y)\n",
    "print(model_to_export)\n",
    "joblib.dump(model_to_export, 'model/classifier.dat.gz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
